{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import enchant\n",
    "from enchant.checker import SpellChecker\n",
    "import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.7.8 (tags/v3.7.8:4b47a5b6ba, Jun 28 2020, 08:53:46) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/labelled/unpreprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of labelled comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20102"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the text more uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preproc'] = df.body.replace(r'http\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change acronyms to words for uniformity. \n",
    "* https://www.netlingo.com/acronyms.php\n",
    "* https://blog.adioma.com/internet-acronyms-intro-list-infographic/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from util.acronyms_smileys import acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.preproc = df.preproc.str.lower()\n",
    "# the ’ was causing issues, took a while to notice\n",
    "df.preproc = df.preproc.str.replace('’', '\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.preproc = df.preproc.apply(lambda x: ' '.join(acronyms.get(word, word) for word in x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of emojis defined from https://en.wikipedia.org/wiki/List_of_emoticons , https://emojipedia.org/people/\n",
    "\n",
    "Other references:\n",
    "* https://www.urbandictionary.com/define.php?term=%F0%9F%92%80\n",
    "* https://www.urbandictionary.com/define.php?term=%F0%9F%94%A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "# list of tagged emoticons from above links\n",
    "from util.acronyms_smileys import smileys\n",
    "from util.acronyms_smileys import sent_acronyms\n",
    "# for removing untagged emoji\n",
    "import demoji\n",
    "#demoji.download_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_repeating_emoji(text):\n",
    "    uniques = set()\n",
    "    final_string = list()\n",
    "    text_arr = [item for item in emoji.get_emoji_regexp().split(text) if not item == '']\n",
    "    for e in text_arr:\n",
    "        # for some reason even though it is defined as '❤', when its \n",
    "        # imported, it gets loaded as '❤❤'\n",
    "        if e == '❤':\n",
    "            e = '❤❤'\n",
    "        if not bool(emoji.get_emoji_regexp().search(e)):\n",
    "            final_string.append(smileys.get(e, e))\n",
    "        else:\n",
    "            if e not in uniques:\n",
    "                uniques.add(e)\n",
    "                final_string.append(smileys.get(e, e))\n",
    "    return ' '.join(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find repeating emoticons and remove repetitions, and tag emoticons\n",
    "df.preproc = df.preproc.apply(lambda x: replace_repeating_emoji(x) if (bool(emoji.get_emoji_regexp().search(x)) and bool(re.search(r'(.)\\1', x))) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove untagged emoticons\n",
    "df.preproc = df.preproc.apply(lambda x : demoji.replace(x, ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set sentiment on acronyms (such as 'lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.preproc = df.preproc.apply(lambda x: ' '.join(sent_acronyms.get(word, word) for word in x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.preproc = df.preproc.apply(lambda x: ' '.join([word for word in x.split() if '#' not in word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>rated</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>date</th>\n",
       "      <th>preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [body, positive, negative, neutral, rated, comment_id, video_id, date, preproc]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.preproc.str.contains('#')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace negations with \"not\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "negations = ['don\\'t', 'aint' 'aren\\'t', 'couldn\\'t','didn\\'t', \n",
    "             'doesn\\'t', 'hadn\\'t', 'hasn\\'t', 'haven\\'t', 'isn\\'t', \n",
    "             'mightn\\'t', 'mustn\\'t', 'needn\\'t', 'shouldn\\'t', 'wasn\\'t', \n",
    "             'weren\\'t', 'won\\'t', 'wouldn\\'t', 'nor', 'not', 'cant', 'dont',\n",
    "            'arent', 'couldnt', 'didnt', 'doesnt', 'hadnt', 'hasnt', 'havent',\n",
    "            'isnt', 'mightnt', 'mustnt', 'neednt', 'shouldnt', 'wasnt',\n",
    "            'werent', 'wont', 'wouldnt']\n",
    "regx = r'\\b(?:{})\\b'.format('|'.join(negations))\n",
    "df.preproc = df.preproc.str.replace(regx, 'not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove negations from stop list, add two missing contractions\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list = [el for el in stopwords_list if el not in negations]\n",
    "missing_words = ['i\\'m', 'i\\'d']\n",
    "stopwords_list.extend(missing_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "singular_pronouns = ['me', 'you', 'he', 'she', 'they', 'his', 'her', 'him']\n",
    "stopwords_list_complete = [x for x in stopwords_list if x not in singular_pronouns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 most commonly used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the      6492\n",
       "i        5519\n",
       "this     4766\n",
       "is       3940\n",
       "you      3794\n",
       "a        3650\n",
       "to       3399\n",
       "and      3072\n",
       "not      2546\n",
       "of       2270\n",
       "it       1971\n",
       "like     1941\n",
       "in       1772\n",
       "that     1646\n",
       "so       1624\n",
       "was      1459\n",
       "are      1367\n",
       "laugh    1352\n",
       "for      1252\n",
       "just     1234\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(' '.join(df.preproc).lower().split()).value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_stopwords(stop_words, n=5):\n",
    "    most_freq_words = pd.Series(' '.join(df.preproc).lower().split()).value_counts()[:int(n*2)].keys().to_numpy()\n",
    "    common_stopwords = [i for i in most_freq_words if i in stopwords_list_complete]\n",
    "    return common_stopwords[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove most common stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stopwords = get_common_stopwords(stopwords_list, n=20)\n",
    "df.preproc = df.preproc.apply(lambda x: ' '.join([word for word in x.split() if word not in (common_stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>rated</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>date</th>\n",
       "      <th>preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*stretched past the 10 minute mark for ad reve...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UgztP4lVR-Epv5HlSXN4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-01-10T20:24:33Z</td>\n",
       "      <td>*stretched past 10 minute mark ad revenue, see!*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That makes no sense you sold a new phone for n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugw3sxLwikkGsUza7hh4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-03-22T19:13:19Z</td>\n",
       "      <td>makes no sense you sold new phone nothing ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY IS HE SO HAPPY HE JUST LOST $900 DOLLARS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugxe5-sz9eHyFCvZX4l4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-10-30T12:27:57Z</td>\n",
       "      <td>why he happy he lost $900 dollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does it work on iPads</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>UgxInsxWP8cnbFEh1Cp4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-07-21T16:38:40Z</td>\n",
       "      <td>does work ipads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yo ass better not have donated.. that cord mig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugwn6_K1_792ARqfY4h4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2019-12-23T13:35:04Z</td>\n",
       "      <td>yo ass better not have donated.. cord might ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  positive  negative  \\\n",
       "0  *stretched past the 10 minute mark for ad reve...         0         1   \n",
       "1  That makes no sense you sold a new phone for n...         0         1   \n",
       "2       WHY IS HE SO HAPPY HE JUST LOST $900 DOLLARS         0         0   \n",
       "3                              Does it work on iPads         0         0   \n",
       "4  Yo ass better not have donated.. that cord mig...         0         0   \n",
       "\n",
       "   neutral  rated                  comment_id     video_id  \\\n",
       "0        0      1  UgztP4lVR-Epv5HlSXN4AaABAg  ItYOdWRo0JY   \n",
       "1        0      1  Ugw3sxLwikkGsUza7hh4AaABAg  ItYOdWRo0JY   \n",
       "2        1      1  Ugxe5-sz9eHyFCvZX4l4AaABAg  ItYOdWRo0JY   \n",
       "3        1      1  UgxInsxWP8cnbFEh1Cp4AaABAg  ItYOdWRo0JY   \n",
       "4        1      1  Ugwn6_K1_792ARqfY4h4AaABAg  ItYOdWRo0JY   \n",
       "\n",
       "                   date                                            preproc  \n",
       "0  2020-01-10T20:24:33Z   *stretched past 10 minute mark ad revenue, see!*  \n",
       "1  2020-03-22T19:13:19Z        makes no sense you sold new phone nothing ?  \n",
       "2  2020-10-30T12:27:57Z                  why he happy he lost $900 dollars  \n",
       "3  2020-07-21T16:38:40Z                                    does work ipads  \n",
       "4  2019-12-23T13:35:04Z  yo ass better not have donated.. cord might ha...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "df.preproc = df.preproc.str.replace('[{}]'.format(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>rated</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>date</th>\n",
       "      <th>preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*stretched past the 10 minute mark for ad reve...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UgztP4lVR-Epv5HlSXN4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-01-10T20:24:33Z</td>\n",
       "      <td>stretched past 10 minute mark ad revenue see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That makes no sense you sold a new phone for n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugw3sxLwikkGsUza7hh4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-03-22T19:13:19Z</td>\n",
       "      <td>makes no sense you sold new phone nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY IS HE SO HAPPY HE JUST LOST $900 DOLLARS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugxe5-sz9eHyFCvZX4l4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-10-30T12:27:57Z</td>\n",
       "      <td>why he happy he lost 900 dollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does it work on iPads</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>UgxInsxWP8cnbFEh1Cp4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-07-21T16:38:40Z</td>\n",
       "      <td>does work ipads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yo ass better not have donated.. that cord mig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugwn6_K1_792ARqfY4h4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2019-12-23T13:35:04Z</td>\n",
       "      <td>yo ass better not have donated cord might have...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  positive  negative  \\\n",
       "0  *stretched past the 10 minute mark for ad reve...         0         1   \n",
       "1  That makes no sense you sold a new phone for n...         0         1   \n",
       "2       WHY IS HE SO HAPPY HE JUST LOST $900 DOLLARS         0         0   \n",
       "3                              Does it work on iPads         0         0   \n",
       "4  Yo ass better not have donated.. that cord mig...         0         0   \n",
       "\n",
       "   neutral  rated                  comment_id     video_id  \\\n",
       "0        0      1  UgztP4lVR-Epv5HlSXN4AaABAg  ItYOdWRo0JY   \n",
       "1        0      1  Ugw3sxLwikkGsUza7hh4AaABAg  ItYOdWRo0JY   \n",
       "2        1      1  Ugxe5-sz9eHyFCvZX4l4AaABAg  ItYOdWRo0JY   \n",
       "3        1      1  UgxInsxWP8cnbFEh1Cp4AaABAg  ItYOdWRo0JY   \n",
       "4        1      1  Ugwn6_K1_792ARqfY4h4AaABAg  ItYOdWRo0JY   \n",
       "\n",
       "                   date                                            preproc  \n",
       "0  2020-01-10T20:24:33Z       stretched past 10 minute mark ad revenue see  \n",
       "1  2020-03-22T19:13:19Z         makes no sense you sold new phone nothing   \n",
       "2  2020-10-30T12:27:57Z                   why he happy he lost 900 dollars  \n",
       "3  2020-07-21T16:38:40Z                                    does work ipads  \n",
       "4  2019-12-23T13:35:04Z  yo ass better not have donated cord might have...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove repeating vowels and consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>rated</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>date</th>\n",
       "      <th>preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UgzHduB8hJNtSSVQJ-t4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2019-03-01T09:31:58Z</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Nice!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UgxB4Ya7EeXjnL2gXrF4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2019-02-11T13:52:23Z</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>U are a kind person😁👏</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UgwTHUgTPBxRu8bz6-l4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2019-01-30T12:56:09Z</td>\n",
       "      <td>you kind person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>this looks good</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UgjVVUkF3LLWNXgCoAEC</td>\n",
       "      <td>PpcNQNJmU9Y</td>\n",
       "      <td>2016-07-14T00:24:28Z</td>\n",
       "      <td>looks good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Cool</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UgzhYX7nMHIoIuivJKB4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2019-01-26T09:37:00Z</td>\n",
       "      <td>cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Another talent Matthew possess .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UgwsvtG8cZmcHp_jynx4AaABAg</td>\n",
       "      <td>0tO_l_Ed5Rs</td>\n",
       "      <td>2019-07-29T22:00:27Z</td>\n",
       "      <td>another talent matthew possess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>I kinda love this.. its not mumble rap b.s plu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugxn2Ag15UkrVAtPDh54AaABAg</td>\n",
       "      <td>0tO_l_Ed5Rs</td>\n",
       "      <td>2020-03-11T22:15:20Z</td>\n",
       "      <td>kinda love this its not mumble rap bs plus mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>love this , mathew you killed it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugy1Wp2qqlNY2212gCt4AaABAg</td>\n",
       "      <td>0tO_l_Ed5Rs</td>\n",
       "      <td>2020-07-31T15:15:35Z</td>\n",
       "      <td>love  mathew you killed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Dang matt you killin it.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugxv28EU_oNlNd7b13h4AaABAg</td>\n",
       "      <td>0tO_l_Ed5Rs</td>\n",
       "      <td>2020-03-24T22:22:26Z</td>\n",
       "      <td>dang matt you killin it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Bruh the good ol days</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugzo7Rf5bNJFl6e5mYR4AaABAg</td>\n",
       "      <td>0tO_l_Ed5Rs</td>\n",
       "      <td>2019-12-28T22:40:42Z</td>\n",
       "      <td>bruh good ol days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  positive  negative  \\\n",
       "117                                               Good         1         0   \n",
       "144                                              Nice!         1         0   \n",
       "229                              U are a kind person😁👏         1         0   \n",
       "273                                    this looks good         1         0   \n",
       "277                                               Cool         1         0   \n",
       "284                   Another talent Matthew possess .         1         0   \n",
       "285  I kinda love this.. its not mumble rap b.s plu...         1         0   \n",
       "287                   love this , mathew you killed it         1         0   \n",
       "290                           Dang matt you killin it.         1         0   \n",
       "291                              Bruh the good ol days         1         0   \n",
       "\n",
       "     neutral  rated                  comment_id     video_id  \\\n",
       "117        0      1  UgzHduB8hJNtSSVQJ-t4AaABAg  ItYOdWRo0JY   \n",
       "144        0      1  UgxB4Ya7EeXjnL2gXrF4AaABAg  ItYOdWRo0JY   \n",
       "229        0      1  UgwTHUgTPBxRu8bz6-l4AaABAg  ItYOdWRo0JY   \n",
       "273        0      1        UgjVVUkF3LLWNXgCoAEC  PpcNQNJmU9Y   \n",
       "277        0      1  UgzhYX7nMHIoIuivJKB4AaABAg  ItYOdWRo0JY   \n",
       "284        0      1  UgwsvtG8cZmcHp_jynx4AaABAg  0tO_l_Ed5Rs   \n",
       "285        0      1  Ugxn2Ag15UkrVAtPDh54AaABAg  0tO_l_Ed5Rs   \n",
       "287        0      1  Ugy1Wp2qqlNY2212gCt4AaABAg  0tO_l_Ed5Rs   \n",
       "290        0      1  Ugxv28EU_oNlNd7b13h4AaABAg  0tO_l_Ed5Rs   \n",
       "291        0      1  Ugzo7Rf5bNJFl6e5mYR4AaABAg  0tO_l_Ed5Rs   \n",
       "\n",
       "                     date                                            preproc  \n",
       "117  2019-03-01T09:31:58Z                                               good  \n",
       "144  2019-02-11T13:52:23Z                                               nice  \n",
       "229  2019-01-30T12:56:09Z                                    you kind person  \n",
       "273  2016-07-14T00:24:28Z                                         looks good  \n",
       "277  2019-01-26T09:37:00Z                                               cool  \n",
       "284  2019-07-29T22:00:27Z                    another talent matthew possess   \n",
       "285  2020-03-11T22:15:20Z  kinda love this its not mumble rap bs plus mat...  \n",
       "287  2020-07-31T15:15:35Z                            love  mathew you killed  \n",
       "290  2020-03-24T22:22:26Z                            dang matt you killin it  \n",
       "291  2019-12-28T22:40:42Z                                  bruh good ol days  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.positive == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/46701245/how-to-replace-multiple-consecutive-repeating-characters-into-1-character-in-pyt\n",
    "df.preproc = df.preproc.apply(lambda x: ' '.join([re.sub(r'(.)\\1{2,}', r'\\1\\1', word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag any sequence of \"ha\" or \"ah\" (for example, \"ahaha\" or \"haha\") as a \"laugh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.preproc = df.preproc.apply(lambda x: ' '.join([re.sub(r'([ha]+[ah]+).*\\1', r'laugh', word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.preproc = df.preproc.str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_rating(row):\n",
    "    if row['positive'] == 1:\n",
    "        return 1\n",
    "    elif row['negative'] == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - negative, 1 - positive, -1 neutral\n",
    "df['rating'] = df.apply(lambda row: assign_rating(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write preprocessed column and the rating to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy relevant columns for later to file write\n",
    "preprocessed = df.filter(['comment_id', 'video_id', 'date', 'preproc', 'rating'], axis=1)\n",
    "preprocessed.columns = ['comment_id', 'video_id', 'date', 'body', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = preprocessed.loc[preprocessed.body != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed.to_csv('../datasets/preprocessed/preprocessed_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed.loc[preprocessed.rating == 1].to_csv('../datasets/preprocessed/preprocessed_pos.csv', index=False)\n",
    "preprocessed.loc[preprocessed.rating == 0].to_csv('../datasets/preprocessed/preprocessed_neg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
